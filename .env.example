# OllaMa URL by default is http://localhost:11434, 
# use http://<your ollama server IP>:11434 for Docker as localhost 
# is not accessible from the container
OLLAMA_URL="http://localhost:11434"
OLLAMA_MODEL="mistral:latest"
# uncomment this line to prevent anonymized telemetry in ChromaDB
#ANONYMIZED_TELEMETRY=False
LLM_PROMPT="
<s> [INST] You are an assistant for question-answering tasks. Use the following pieces of retrieved context 
to answer the question. If you don't know the answer, just say that you don't know. Use three sentences
maximum and keep the answer concise. And answer according to the language of the user's question. [/INST] </s> 
[INST] Question: {question} 
Context: {context} 
Answer: [/INST]
"